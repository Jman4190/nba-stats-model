{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing to competitors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_proj = pd.read_csv('nba-csv/player_proj_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert current columns to similar competitor columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['player_name',\n",
    "           'player_id',\n",
    "           'proj_pts',\n",
    "           'proj_min',\n",
    "           'proj_fgm',\n",
    "           'proj_fga',\n",
    "           'proj_fg3m',\n",
    "           'proj_fg3a',\n",
    "           'proj_ftm',\n",
    "           'proj_fta',\n",
    "           'proj_oreb',\n",
    "           'proj_dreb',\n",
    "           'proj_ast',\n",
    "           'proj_stl',\n",
    "           'proj_tov',\n",
    "           'proj_blk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proj_final = player_proj.loc[:, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proj_final['proj_fg%'] = df_proj_final['proj_fgm']  / df_proj_final['proj_fga']\n",
    "df_proj_final['proj_ft%'] = df_proj_final['proj_ftm'] + df_proj_final['proj_fta']\n",
    "df_proj_final['proj_reb'] = df_proj_final['proj_oreb'] + df_proj_final['proj_dreb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_columns = ['player_name',\n",
    "           'player_id',\n",
    "           'proj_pts',\n",
    "           'proj_reb',\n",
    "           'proj_ast',\n",
    "           'proj_blk',\n",
    "           'proj_stl',\n",
    "           'proj_fg%',\n",
    "           'proj_ft%',\n",
    "           'proj_fg3m',\n",
    "           'proj_min',\n",
    "           'proj_tov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proj_final = df_proj_final[final_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in competitor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in projections to dataframe\n",
    "df_comp_1 = pd.read_csv('nba-csv/ESPN_CBS_FantasyPros_Fantasy_Basketball_Overall_2018_Average_Projections.csv')\n",
    "#df_comp_2 = pd.read_csv('Hashtag_CBS_FantasyPros_Fantasy_Basketball_Overall_2018_Average_Projections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Team', 'Positions', 'GP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_1.drop(columns = columns_to_drop, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find names and match to player_id\n",
    "lowercase_names = df_comp_1['Player'].str.lower()\n",
    "df_comp_1['Player'] = lowercase_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase_names.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with player_name\n",
    "player_df = pd.read_csv('nba-csv/player_name_player_id_all_seasons_final.csv')\n",
    "season = player_df['season_id'] == '2016-17'\n",
    "player_df = player_df[season]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase = player_df['player_name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df['player_name'] = lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_merged = pd.merge(df_comp_1, player_df[['player_name','player_id']], how = 'left', left_on = 'Player', right_on = 'player_name').drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_merged.dropna(how = 'any', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_merged.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_ids = comp_merged['player_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_merged['player_id'] = player_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del comp_merged['Player']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'player_name',\n",
    "    'player_id',\n",
    "    'PTS',\n",
    "    'REB',\n",
    "    'AST',\n",
    "    'BLK',\n",
    "    'STL',\n",
    "    'FG%',\n",
    "    'FT%',\n",
    "    '3PM',\n",
    "    'MIN',\n",
    "    'TO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_merged = comp_merged[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_merged.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = player_proj.loc[:, ['player_name', 'player_id', 'pts','min','fgm','fga','fg3m','fg3a','ftm','fta','oreb','dreb','ast','stl','tov', 'blk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real['fg%'] = df_real['fgm']  / df_real['fga']\n",
    "df_real['ft%'] = df_real['ftm'] + df_real['fta']\n",
    "df_real['reb'] = df_real['oreb'] + df_real['dreb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_real_columns = ['player_name',\n",
    "           'player_id',\n",
    "           'pts',\n",
    "           'reb',\n",
    "           'ast',\n",
    "           'blk',\n",
    "           'stl',\n",
    "           'fg%',\n",
    "           'ft%',\n",
    "           'fg3m',\n",
    "           'min',\n",
    "           'tov']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real_final = df_real[final_real_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitor_final = pd.merge(comp_merged, df_real_final, how = 'left', on = 'player_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitor_final.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp drop until I run player_comparison_tool for all players\n",
    "competitor_proj = competitor_final.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = competitor_proj.loc[:, ['pts','reb','ast','blk','stl','fg%','ft%','fg3m','min','tov']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proj = competitor_proj.loc[:, ['PTS','REB','AST','BLK','STL','FG%','FT%','3PM','MIN','TO']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean square error\n",
    "lin_mse = mean_squared_error(df_real, df_proj, multioutput='raw_values')\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "confidence = np.mean(lin_rmse)\n",
    "print('{0} percent confidence in projected {1} per game stats'.format(100 - round(confidence, 2), '2016-17'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match up against our model for same stat columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proj_final.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = pd.merge(df_proj_final, df_real_final, how = 'left', on = 'player_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = model_final.loc[:, ['pts','reb','ast','blk','stl','fg%','ft%','fg3m','min','tov']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proj = model_final.loc[:, ['proj_pts','proj_reb','proj_ast','proj_blk','proj_stl','proj_fg%','proj_ft%','proj_fg3m','proj_min','proj_tov']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean square error\n",
    "lin_mse = mean_squared_error(df_real, df_proj, multioutput='raw_values')\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "confidence = np.mean(lin_rmse)\n",
    "print('{0} percent confidence in projected {1} per game stats'.format(100 - round(confidence, 2), '2016-17'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
